{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tendiek/classifierpredict/blob/master/AC_Predict_Starter_Nbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vYjKmj-vH1B"
      },
      "source": [
        "# Advanced Classification Predict\n",
        "\n",
        "© Explore Data Science Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RsYLeMbvH1F"
      },
      "source": [
        "## Honour Code\n",
        "\n",
        "I **YOUR NAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
        "\n",
        "Non-compliance with the honour code constitutes a material breach of contract."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb4GvE-WvH1G"
      },
      "source": [
        "### Import Libraries and Read In the Data\n",
        "\n",
        "Do not modify or remove any of the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ieL_yYNvH1H",
        "outputId": "f63cf063-194a-45cd-c88d-abf6903705bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import IFrame\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import imblearn\n",
        "import csv\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.tokenize import  word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors  import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse.csr import csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import string\n",
        "import urllib\n",
        "import math\n",
        "import re\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TXrNEOtzvH1J",
        "outputId": "77ca846c-d59d-4dd8-aa7a-70218a645819"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f99e249e-bb80-4ed3-8767-98a256ed4c8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f99e249e-bb80-4ed3-8767-98a256ed4c8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f99e249e-bb80-4ed3-8767-98a256ed4c8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f99e249e-bb80-4ed3-8767-98a256ed4c8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train  = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv') # no labels\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uuSfROvZvH1K",
        "outputId": "2848fc01-c63c-4409-cef6-6af505fd0da3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             message  tweetid\n",
              "0  Europe will now be looking to China to make su...   169760\n",
              "1  Combine this with the polling of staffers re c...    35326\n",
              "2  The scary, unimpeachable evidence that climate...   224985\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d52e478f-8fd5-4849-ab43-3a3a92badacc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d52e478f-8fd5-4849-ab43-3a3a92badacc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d52e478f-8fd5-4849-ab43-3a3a92badacc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d52e478f-8fd5-4849-ab43-3a3a92badacc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxRF8qp4vH1K"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Refer to this diagram to guide you while you build your model. Some of the steps will be fleshed out in this template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYMLgYe_vH1L"
      },
      "source": [
        "![Overview](process_overview_final.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXe6c6i-vH1L"
      },
      "source": [
        "## Basic preprocessing\n",
        "\n",
        "Here is a template you may use for your initial base model. \n",
        "\n",
        "### Removing URL's\n",
        "Write a function that removes URL's from a single tweet. \n",
        "\n",
        "**Function input:**\n",
        "- A single string object (tweet) \n",
        "\n",
        "**Function output:**\n",
        "- The tweet with URL's removed as a single object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QNC_Wl8kvH1L"
      },
      "outputs": [],
      "source": [
        "# define function that removes URL from single tweet\n",
        "def remove_urls(text):\n",
        "    # YOUR CODE HERE \n",
        "    processed_text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnsnXT8ovH1M"
      },
      "source": [
        "**Original object:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y0jxDSWUvH1M",
        "outputId": "69736478-6a46-4b3c-8fb2-e9f05247f2ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tweet = train['message'][2]\n",
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9Cy7lWRgvH1N",
        "outputId": "bb9321d4-918d-4973-9c92-de4841f24c99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "remove_urls(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CYeEY1VvH1N"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "remove_urls(tweet)\n",
        "\n",
        ">>'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late  '\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXP-6PG9vH1O"
      },
      "source": [
        "### Convert to lowercase\n",
        "\n",
        "Write a function that converts a single tweet to lowercase.\n",
        "\n",
        "**Function input:**\n",
        "- A single string object (tweet) \n",
        "\n",
        "**Function output:**\n",
        "- The tweet in lowercase as a single object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YC6eQrxXvH1O"
      },
      "outputs": [],
      "source": [
        "def to_lower(text):\n",
        "    # YOUR CODE HERE \n",
        "    lower_text = text.lower()\n",
        "    return lower_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdMnzKWVvH1P"
      },
      "source": [
        "**Original object:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DbxuXPd4vH1P",
        "outputId": "a605870a-3137-4f13-9ad6-67bb5351cc20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ebSMEjmHvH1P",
        "outputId": "37209266-ddac-460f-cbf4-d5f45cdecf2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rt @rawstory: researchers say we have three years to act on climate change before it’s too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "to_lower(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fA1CH8CvH1Q"
      },
      "source": [
        "**Expected output:**\n",
        "\n",
        "```python \n",
        "to_lower(tweet)\n",
        ">> 'rt @rawstory: researchers say we have three years to act on climate change before it’s too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'\n",
        "```\n",
        "\n",
        "### Stemming or lemmatising\n",
        "\n",
        "Write a function that derives the root words for each of the words in a tweet. You may use stemming _or_ lemmatising here.\n",
        "\n",
        "**Function input:**\n",
        "- A single string object (tweet) \n",
        "\n",
        "**Function output:**\n",
        "- The tweet in root words as a _single_ object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t25nb2SdvH1Q"
      },
      "outputs": [],
      "source": [
        "def get_roots(text):\n",
        "    # YOUR CODE HERE \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    root_text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "    return ' '.join(root_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DKYOzmwvH1R"
      },
      "source": [
        "**Original object:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Or0JrGwDvH1R",
        "outputId": "9a01c69e-19ee-4ab0-ac98-673062b1f08b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_roots(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ePnxp8P2YqaB",
        "outputId": "6bfa1811-875f-49af-e908-2997e56d07e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three year to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL1YhP3ivH1S"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "get_roots(tweet)\n",
        "```\n",
        "Using `SnowballStemmer()`\n",
        "```python\n",
        ">> 'rt @rawstory: research say we have three year to act on climat chang befor it too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'\n",
        "```\n",
        "\n",
        "Using `WordNetLemmatizer()`\n",
        "```python\n",
        ">> 'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnkomUD5vH1S"
      },
      "source": [
        "### Other preprocessing techniques \n",
        "\n",
        "Come back here once you have submitted your base model to add any other preprocessing functions yuo wish to add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lt85PE1vH1S"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5uDr438vH1T"
      },
      "source": [
        "### Tokenising \n",
        "\n",
        "Write a function that tokenises a single tweet into a list of tokens.\n",
        "\n",
        "**Function input:**\n",
        "- A single string object (tweet) \n",
        "\n",
        "**Function output:**\n",
        "- A list of tokens (objects)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sCxYfNxRvH1T"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "    # YOUR CODE HERE \n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QO8IzvpvH1U"
      },
      "source": [
        "**Original object:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vo8HJKXtvH1U",
        "outputId": "c8435220-7b3c-43af-e702-ac56944f6ba9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7C5llUYvH1U",
        "outputId": "c2669ff7-6698-4f32-94ee-333e563d416f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'RawStory',\n",
              " ':',\n",
              " 'Researchers',\n",
              " 'say',\n",
              " 'we',\n",
              " 'have',\n",
              " 'three',\n",
              " 'years',\n",
              " 'to',\n",
              " 'act',\n",
              " 'on',\n",
              " 'climate',\n",
              " 'change',\n",
              " 'before',\n",
              " 'it',\n",
              " '’',\n",
              " 's',\n",
              " 'too',\n",
              " 'late',\n",
              " 'https',\n",
              " ':',\n",
              " '//t.co/WdT0KdUr2f',\n",
              " 'https',\n",
              " ':',\n",
              " '//t.co/Z0ANPT…']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "get_tokens(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iRau9NFvH1V"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "get_tokens(tweet)\n",
        "\n",
        ">> ['RT',\n",
        " '@',\n",
        " 'RawStory',\n",
        " ':',\n",
        " 'Researchers',\n",
        " 'say',\n",
        " 'we',\n",
        " 'have',\n",
        " 'three',\n",
        " 'years',\n",
        " 'to',\n",
        " 'act',\n",
        " 'on',\n",
        " 'climate',\n",
        " 'change',\n",
        " 'before',\n",
        " 'it’s',\n",
        " 'too',\n",
        " 'late',\n",
        " 'https',\n",
        " ':',\n",
        " '//t.co/WdT0KdUr2f',\n",
        " 'https',\n",
        " ':',\n",
        " '//t.co/Z0ANPT…']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0qHYMwbvH1V"
      },
      "source": [
        "Besides the preprocessing methods we've already discussed, can you think of how our data can be improved at this stage?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zQXw22IvH1V"
      },
      "source": [
        "### Vectorising \n",
        "\n",
        "Use the code from the webinar to define your vecotiser. For more details on this function have a look at the `sklearn`\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">package documentation on the function</a>. Recall that this function, unlike the others before takes an _**entire column**_ as an argument.\n",
        "\n",
        "### Putting all the functions together \n",
        "\n",
        "Test your cleaning functions on a single tweet. Perform the cleaning procedure on this tweet from start to finish. Make sure the output looks as you would expect. Store the cleaned tweet in `tweet_final`. Don't worry about vectorising for now.\n",
        "\n",
        "**_Include any other cleaning procedures you add after your base model_**\n",
        "\n",
        "**Original object:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lL4iwFs9vH1V",
        "outputId": "ab30f2be-146e-47ef-ca7a-b751d78607c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-dW2x5YvH1W",
        "outputId": "f33c3815-4cb6-491b-846f-2e788c2b8aa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " '@',\n",
              " 'rawstory',\n",
              " ':',\n",
              " 'researcher',\n",
              " 'say',\n",
              " 'we',\n",
              " 'have',\n",
              " 'three',\n",
              " 'year',\n",
              " 'to',\n",
              " 'act',\n",
              " 'on',\n",
              " 'climate',\n",
              " 'change',\n",
              " 'before',\n",
              " 'it',\n",
              " '’',\n",
              " 's',\n",
              " 'too',\n",
              " 'late']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# clean tweet from start to finish\n",
        "tweet1 = remove_urls(tweet)\n",
        "tweet2 = to_lower(tweet1)\n",
        "tweet3 = get_roots(tweet2)\n",
        "tweet_final = get_tokens(tweet3)\n",
        "#.\n",
        "#.\n",
        "\n",
        "# cleaned tweet\n",
        "tweet_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7WQH8IvH1W"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "tweet_final\n",
        ">>['rt',\n",
        " '@',\n",
        " 'rawstory',\n",
        " ':',\n",
        " 'research',\n",
        " 'say',\n",
        " 'we',\n",
        " 'have',\n",
        " 'three',\n",
        " 'year',\n",
        " 'to',\n",
        " 'act',\n",
        " 'on',\n",
        " 'climat',\n",
        " 'chang',\n",
        " 'befor',\n",
        " 'it',\n",
        " 'too',\n",
        " 'late']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAsMufZDvH1X"
      },
      "source": [
        "### Preprocessing and cleaning entire column of tweets\n",
        "\n",
        "Now that we know how to clean a single tweet, we can use `apply()` to clean the entire column in the dataframe. This is what the column looks like to begin with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg7V11oAvH1X",
        "outputId": "b4793eaa-ccc2-40a6-c6de-8f96e5fafc30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    PolySciMajor EPA chief doesn't think carbon di...\n",
              "1    It's not like we lack evidence of anthropogeni...\n",
              "2    RT @RawStory: Researchers say we have three ye...\n",
              "3    #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
              "4    RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n",
              "Name: message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train['message'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAfscxqfvH1X"
      },
      "source": [
        "Write code that applies your cleaning functions to the entire `message` column of the dataframe using `.apply()`. Do not vectorise just yet. Store this in a new column, `train['message_clean']`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTU6-s3dvH1Y",
        "outputId": "93849391-b4d3-4620-a945-c2d621f53fc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [PolySciMajor, EPA, chief, does, n't, think, c...\n",
              "1    [It, 's, not, like, we, lack, evidence, of, an...\n",
              "2    [RT, @, RawStory, :, Researchers, say, we, hav...\n",
              "3    [#, TodayinMaker, #, WIRED, :, 2016, was, a, p...\n",
              "4    [RT, @, SoyNovioDeTodas, :, It, 's, 2016, ,, a...\n",
              "Name: message_clean, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# applying cleaning functions to entire column of dataframe (NO VECTORISING)\n",
        "\n",
        "# YOUR CODE HERE - use apply with all your cleaning functions \n",
        "\n",
        "train['message_clean'] = train['message'].apply(get_roots)\n",
        "train['message_clean'] = train['message'].apply(get_tokens)\n",
        "train['message_clean'] = train['message'].apply(remove_urls)\n",
        "train['message_clean'] = train['message'].apply(to_lower)\n",
        "train['message_clean'] = train['message'].apply(get_roots)\n",
        "train['message_clean'] = train['message'].apply(get_tokens)\n",
        "#train['message_clean']= train['message'].apply(lambda x: (', '.join([x for x in [remove_urls, to_lower, get_roots, get_tokens] if x != None])))\n",
        "train['message_clean'].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDlqmmfKvH1Y"
      },
      "source": [
        "**Expected output:**\n",
        "\n",
        "```python\n",
        "train['message_clean'].head()\n",
        "\n",
        ">>  0    [polyscimajor, epa, chief, does, n't, think, c...\n",
        "    1    [it, not, like, we, lack, evid, of, anthropoge...\n",
        "    2    [rt, @, rawstory, :, research, say, we, have, ...\n",
        "    3    [#, todayinmaker, #, wire, :, 2016, was, a, pi...\n",
        "    4    [rt, @, soynoviodetodas, :, it, 2016, ,, and, ...\n",
        "Name: message_clean, dtype: object\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_prep(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub(r\"\\bhttps://t.co/\\w+\", '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text) \n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ',text.lower()) \n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "h9cZxCb4LkSP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Btq1RZ2M5Wp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_TG_ejvH1Y"
      },
      "source": [
        "### Vectorising \n",
        "\n",
        "Vectorise your cleaned data using the vectoriser you defined earlier. Don't forget to fit the vectoriser to the data you just cleaned. Store your vectorised data in `train_vec`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['sentiment']\n",
        "X = train['message']"
      ],
      "metadata": {
        "id": "z_oHKix-lFZi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pvuWdR3YvH1Y"
      },
      "outputs": [],
      "source": [
        "# vectorise your cleaned data\n",
        "\n",
        "# YOUR CODE HERE \n",
        "vect = CountVectorizer(ngram_range=(1,3),\n",
        "                           max_df = 0.7, min_df = 3, \n",
        "                           preprocessor=tweet_prep, \n",
        "                           tokenizer=get_tokens, \n",
        "                           stop_words='english')\n",
        "X_vectorized = vect.fit_transform(train['message'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWWukHyAvH1Z"
      },
      "source": [
        "## Fitting a simple model on training data and evaluate its performance\n",
        "\n",
        "Fit a model on your cleaned data. Use `train_vec` as your features. Note that you need to convert `train_vec` to an array. \n",
        "\n",
        "You are familiar with this process, so there is less guidance here. You may also refer to train notebooks and the webinar pdf as guidance.\n",
        "\n",
        "Your basic model should be a logistic regression, however if you try different models you will also perform the following procedure.\n",
        "\n",
        "1. Split the training data into features and labels.\n",
        "2. Split the training data further into training and validation data.\n",
        "3. Fit the model on the training subset. \n",
        "4. Predict on the validation subset.\n",
        "5. Calculate the performance metrics on the validation predictions.\n",
        "6. Select a model based on validation performance (when you have more than one model).\n",
        "8. Clean the test data.\n",
        "9. Predict on the cleaned test data.\n",
        "7. Write a csv that matches `sample_submission.csv`.\n",
        "8. Submit to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iVH_JvvjvH1Z"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE \n",
        "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.2,shuffle=True, random_state=12)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_val)"
      ],
      "metadata": {
        "id": "tdfBS-9flrAp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, rfc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hljA0nUTly__",
        "outputId": "7d64192c-b7cd-4ad6-b46e-139f8b9a4e74"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5803636764937878"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lc = LogisticRegression(C=1.05, penalty='l2', solver='sag', verbose=1)\n",
        "lc.fit(X_train, y_train)\n",
        "lc_pred = lc.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWqVoA1bpUJJ",
        "outputId": "2995fea4-c2f8-4f38-a242-28c90e6052cc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter reached after 1 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, lc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vriFAo3qTQj",
        "outputId": "9b6c9a37-a063-491d-f48a-11e79571bd14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6545341117476889"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nnc = KNeighborsClassifier(3)\n",
        "nnc.fit(X_train, y_train)\n",
        "nnc_pred = nnc.predict(X_val)"
      ],
      "metadata": {
        "id": "hTYEo5bGreyd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, nnc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnNmMjNir8qp",
        "outputId": "c66f7e33-1eb6-4d81-883b-41001cb7bee9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4269186502462132"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LinearSVMC = SVC(kernel=\"linear\", C=0.095)\n",
        "LinearSVMC.fit(X_train, y_train)\n",
        "LinearSVMC_pred = LinearSVMC.predict(X_val)"
      ],
      "metadata": {
        "id": "t77DWMJkufOu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, LinearSVMC_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rPt_VQAvaQB",
        "outputId": "4d12dcbe-be28-4695-f485-829cae568ec3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6225818586188329"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = DecisionTreeClassifier(max_depth=9)\n",
        "dtc.fit(X_train, y_train)\n",
        "dtc_pred = dtc.predict(X_val)"
      ],
      "metadata": {
        "id": "-NcU5WDhvj93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, dtc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g8IaaWEv2fF",
        "outputId": "0ab6e94b-9a55-4161-cc33-b07af68a67c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33352437755156267"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbc = MultinomialNB()\n",
        "nbc.fit(X_train, y_train)\n",
        "nbc_pred = nbc.predict(X_val)"
      ],
      "metadata": {
        "id": "cIeZHZ2hwBFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, nbc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLnzKgE3wFhk",
        "outputId": "47ee4737-3a55-4e50-f964-e24168b2524e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6129523633613259"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rbfsvmc = SVC(gamma=2, C=1)\n",
        "rbfsvmc.fit(X_train, y_train)\n",
        "rbfsvmc_pred = rbfsvmc.predict(X_val)"
      ],
      "metadata": {
        "id": "8DXMuQpr3M49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, rbfsvmc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnjehalo3Nh6",
        "outputId": "70b04718-a310-4ce7-9b84-2c3324755120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32433003894249485"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc = XGBClassifier(max_depth=6)\n",
        "xgbc.fit(X_train, y_train)\n",
        "xgbc_pred = xgbc.predict(X_val)"
      ],
      "metadata": {
        "id": "oDt1tp4e7RbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, xgbc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfp3vcYf7U9A",
        "outputId": "2ec04be5-2702-4c55-bc2c-17519763a8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5147134960630859"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adc = AdaBoostClassifier()\n",
        "adc.fit(X_train, y_train)\n",
        "adc_pred = adc.predict(X_val)"
      ],
      "metadata": {
        "id": "wi1dK9r77-PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, adc_pred, average=\"macro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxCYyRph7-dY",
        "outputId": "4409a828-6ac7-4baa-a2e7-0591220ca180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4624551342839262"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QbgzLHbvH1Z"
      },
      "source": [
        "## Suggestions on how to improve the model - Extras \n",
        "\n",
        "Here are some ideas on how you can improve your model. Try some of them out once you have submitted your base model to Kaggle. Only use the methods you find improve your model performance.\n",
        "\n",
        " - Additional preprocessing \n",
        "     - Use some of the methods in the notebooks to balance the data\n",
        "     - Replace links with the text `Link` to show the machine that there is a link present without the extraneous detail of the link text\n",
        "     - Remove punctuation\n",
        "     - Correct spelling\n",
        "     - Bag of words vs. N-grams - which is better?\n",
        "     - Try `TweetTokenizer()` - how does this differ from the tokenisers you are familiar with?\n",
        " - Consider which other models could do a better job (refer to course resources)\n",
        " - Consider some further feature engineering:\n",
        "     - What other attributes of the tweets may be useful?\n",
        "     - Should we perform feature selection given their size and sparseness of the vectorised tweets?\n",
        " - If you've mastered the above, try implementing hyperparameter tuning methods.\n",
        " - Compare all the models you try and remember to submit **the best one** based on test performance (f1-score using macro averaging). \n",
        " \n",
        "You may use the space below to try out these \"Extras\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYIUlmUGvH1a"
      },
      "outputs": [],
      "source": [
        "# Extras\n",
        "# YOUR CODE HERE \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQhWLhCAvH1a"
      },
      "source": [
        "## How/why is the model bad?\n",
        "\n",
        "Do you have any hypotheses as to how you can improve the model further? Use this space to investigate with mindful EDA if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Uf-PT8vH1a"
      },
      "outputs": [],
      "source": [
        "# EDA\n",
        "# YOUR CODE HERE \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBy_8kZJvH1a"
      },
      "source": [
        "Be sure to check whether each additional technique you apply actually improves your model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9sTy267vH1a"
      },
      "source": [
        "## Submit your best model predictions \n",
        "\n",
        "Don't forget to submit your the predictions on the best model to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testx = test['message']\n",
        "test_vect = vect.transform(testx)"
      ],
      "metadata": {
        "id": "KpSW5CNsGBbP"
      },
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lc.predict(test_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "aGpWUqIlGEFk",
        "outputId": "877723ca-31af-46ec-9cc9-e21050c45c81"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-493-3deac83e9077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 12956 features, but LogisticRegression is expecting 19211 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['sentiment'] = y_pred"
      ],
      "metadata": {
        "id": "QhM18fG1GgaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "d5ee550e-641d-4f25-c44e-2c7223cc5980"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-429-3093df314a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "wYqt53HQGlGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2c62d029-d59c-44e6-9fdf-473543c07ade"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             message  tweetid\n",
              "0  Europe will now be looking to China to make su...   169760\n",
              "1  Combine this with the polling of staffers re c...    35326\n",
              "2  The scary, unimpeachable evidence that climate...   224985\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95633ba2-845f-49c7-a161-2b4802221697\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95633ba2-845f-49c7-a161-2b4802221697')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95633ba2-845f-49c7-a161-2b4802221697 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95633ba2-845f-49c7-a161-2b4802221697');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4odeSR4vH1b"
      },
      "outputs": [],
      "source": [
        "# write csv for best predictions\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "AC_Predict_Starter_Notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}